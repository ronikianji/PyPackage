{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "426b322e-029d-49ed-9f40-10b5a9b24bfe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Libraries installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c4c98-1d50-4603-9565-7135e5731079",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rioxarray\n",
    "!pip install ruptures\n",
    "!pip install scikit-learn\n",
    "!pip install bayesian-changepoint-detection\n",
    "!pip install netCDF4\n",
    "!pip install xarray\n",
    "!pip install basemap\n",
    "!pip install geopandas\n",
    "!pip install cartopy\n",
    "!pip install pandas\n",
    "!pip install dask\n",
    "!pip install --upgrade xarray dask\n",
    "!pip install numpy pandas matplotlib seaborn scikit-learn tensorflow keras nltk spacy beautifulsoup4 requests scipy statsmodels plotly bokeh gensim Pillow\n",
    "!pip install numpy pandas matplotlib seaborn scikit-learn tensorflow keras nltk spacy beautifulsoup4 requests\n",
    "!pip install numpy pandas matplotlib seaborn scikit-learn\n",
    "!pip install dask[dataframe]\n",
    "!pip install openpyxl\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6652021b-c38f-405b-aca1-a92b3ed29a2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## NetCDF4 file reading (info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5d3902-383f-4e19-a885-52641c117634",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### You can use anyone of the below code to see the details of the NetCDF4 file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50cf623-7aa9-4b13-abbc-5ab8d35039ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "ds = xr.open_dataset(\"your_file.nc\")  # Replace \"your_file.nc\" with the actual file path of your NetCDF file\n",
    "ds.info()                             # Provides a concise summary of the datasetâ€™s structure and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61228317-15cb-4ed4-9494-183c41915b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4  \n",
    "print(netCDF4.Dataset(\"your_file.nc\"))  # Replace \"your_file.nc\" with the path to your NetCDF file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6f4f64-cc90-459b-bb7f-1f4153c17c35",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### To know the details about a particular variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f751c4-b623-4a68-bbfb-10a924b4b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc \n",
    "file_path = \"your_file.nc\"  # Replace with the path to your NetCDF file\n",
    "dataset = nc.Dataset(file_path, 'r')  \n",
    "print(dataset)  \n",
    "print(\"Here are all the variables of your data\") \n",
    "print(dataset.variables.keys())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45c2cb9-6298-4525-9971-24f215ced873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_variable' with the actual variable name you want to access from the dataset\n",
    "your_variable = dataset.variables['your_variable']  \n",
    "your_variable_data = your_variable[:]  \n",
    "\n",
    "print(\"Shape of your_variable_data:\", your_variable_data.shape)      # Prints the shape of the data\n",
    "print(\"Data type of your_variable_data:\", your_variable_data.dtype)  # Prints the data type of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e81c25-6d05-4121-83f0-128f3acc0b51",
   "metadata": {},
   "source": [
    "### NetCDF4 (.nc) file to data frame (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb1ce52-94af-407c-af86-e57c389e5496",
   "metadata": {},
   "source": [
    "#### Creation of DataFrame  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755631b6-1476-42aa-bcf6-677a196afc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr \n",
    "ds = xr.open_dataset(\"your_file.nc\")  # Replace \"your_file.nc\" with the path to your NetCDF file\n",
    "\n",
    "df = ds.to_dataframe().reset_index()  # Replace 'df' with the name you want to initialize for your DataFrame\n",
    "\n",
    "# Display the DataFrame\n",
    "df  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db497d9-eac8-4bb8-9b08-9e9e8ed143a8",
   "metadata": {},
   "source": [
    "#### To create the data frame for a particular variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96b5199-fba2-47ee-8469-1cd1ac8f54cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import netCDF4 as nc  \n",
    "import numpy as np  \n",
    "\n",
    "file_path = \"your_file.nc\"                       # Replace 'your_file.nc' with the path to your actual NetCDF file\n",
    "\n",
    "# Open the NetCDF file for reading\n",
    "with nc.Dataset(file_path, 'r') as dataset:  \n",
    "    time_var = dataset.variables['time'][:]      # Replace 'time' with the actual variable name for the time in your file\n",
    "    lat_var = dataset.variables['lat'][:]        # Replace 'lat' with the actual variable name for latitude\n",
    "    lon_var = dataset.variables['lon'][:]        # Replace 'lon' with the actual variable name for longitude\n",
    "    data_var = dataset.variables['variable'][:]  # Replace 'variable' with the actual variable name for data\n",
    "\n",
    "time_2d, lat_2d, lon_2d = np.meshgrid(time_var, lat_var, lon_var, indexing='ij')  \n",
    "data_1d = data_var.flatten()  \n",
    "df = pd.DataFrame({                              # Replace 'df' with the name you want to initialize for your DataFrame\n",
    "    'time': time_2d.flatten(),  \n",
    "    'lat': lat_2d.flatten(),   \n",
    "    'lon': lon_2d.flatten(),    \n",
    "    'variable': data_1d        \n",
    "})\n",
    "df  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9620b44-2ef6-49a7-8f8d-cb030982460b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data Transformation and Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e021cb3-ab30-4d6a-917d-5a7ea333ae08",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2e9670-aeb8-40c6-8fcb-0fe2c0045019",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### CSV to NetCDF(nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7284f6cc-e8e1-458d-8e09-fad940619caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import xarray as xr \n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "csv_file = \"your_file.csv\"      # Specify the path to your CSV file\n",
    "df = pd.read_csv(csv_file)  \n",
    "\n",
    "# Convert the DataFrame into an xarray Dataset\n",
    "ds = xr.Dataset.from_dataframe(df) \n",
    "\n",
    "# Save the xarray Dataset as a NetCDF file\n",
    "netcdf_file = \"output_file.nc\"  # Specify the path where you want to save the NetCDF file\n",
    "ds.to_netcdf(netcdf_file)  \n",
    "\n",
    "# Print a message indicating that the conversion is complete\n",
    "print(f\"CSV file '{csv_file}' has been converted to NetCDF '{netcdf_file}'\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e793824b-5c31-4f20-b278-55fc1cc9104c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### DataFrame(df) to NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f536b868-db72-4021-a90d-f95dc96c765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr \n",
    "\n",
    "# Replace 'ds' with the desired name to save the NetCDF file.\n",
    "ds = xr.Dataset.from_dataframe(df)        # Replace `df` with the name of your DataFrame\n",
    "\n",
    "ds.to_netcdf('your_output_file.nc')       # Replace 'your_output_file.nc' with the desired path where you want to save the NetCDF file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9c4055-7064-41ff-8264-1870790367c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Excel to NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef49509-7884-4c0b-9a9c-91cc13fe6e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import xarray as xr  \n",
    "\n",
    "# Read the Excel file into a Pandas DataFrame\n",
    "excel_file = \"your_file.xlsx\"  # Specify the path to your Excel file\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Convert the DataFrame into an xarray Dataset\n",
    "ds = xr.Dataset.from_dataframe(df) \n",
    "\n",
    "# Save the xarray Dataset as a NetCDF file\n",
    "netcdf_file = \"output_file.nc\"  # Specify the path where you want to save the NetCDF file\n",
    "ds.to_netcdf(netcdf_file)  \n",
    "\n",
    "# Print a message indicating that the conversion is complete\n",
    "print(f\"Excel file '{excel_file}' has been converted to NetCDF '{netcdf_file}'\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b41ec2-273c-446f-96ff-74225c20e0ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Resampling of  file from one resolution to another resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f506275a-9f4c-4e50-9fc0-db888d38c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr  \n",
    "import numpy as np \n",
    "\n",
    "# Load the NetCDF data\n",
    "data = xr.open_dataset(\"your_input_file.nc\")  # Replace 'your_input_file.nc' with your actual NetCDF file path\n",
    "\n",
    "# Define new latitude and longitude coordinates with 0.25Â° resolution\n",
    "# (You can adjust these values(0.25Â°) based on your resolution requirement)\n",
    "new_lon = np.arange(data.lon.min(), data.lon.max(), 0.25)  # Longitudes\n",
    "new_lat = np.arange(data.lat.min(), data.lat.max(), 0.25)  # Latitudes \n",
    "\n",
    "# Resample the data to new spatial resolution (0.25Â° Ã— 0.25Â°)\n",
    "# (You can change 'linear' to another interpolation method if needed)\n",
    "resampled_data = data.interp(lon=new_lon, lat=new_lat, method='linear')  # Linear\n",
    "\n",
    "print(resampled_data)  \n",
    "\n",
    "# Save the resampled data to a new NetCDF file\n",
    "resampled_data.to_netcdf('your_output_file.nc')  # Replace 'your_output_file.nc' with your desired output file name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a41fac9-a818-422d-96c3-0947c7423813",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Longitude format change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25482bf-28fe-4dab-b773-f9076b5e8a99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Convert longitude from -180 to 180 to 0 to 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08029ac-db0f-4b72-9350-230ea3fb880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "\n",
    "resolution = 0.25  ### Replace '0.25' with the resolution of your data ###\n",
    "\n",
    "adjustment = resolution / 2\n",
    "df['lon'] = df['lon'].apply(lambda x: ((x + 180) % 360) - adjustment)   # Replace `df` with your DataFrame name\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0060f50-4afc-4d4a-ae7c-299e8b0d7e82",
   "metadata": {},
   "source": [
    "#### Convert longitude from 0 to 360 to -180 to 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c4614b-0fe9-4208-ac6f-6788c6fd8d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "\n",
    "resolution = 0.25  ### Replace '0.25' with the resolution of your data ###\n",
    "\n",
    "adjustment = resolution / 2\n",
    "df['lon'] = df['lon'].apply(lambda x: ((x + adjustment) % 360) - 180)   # Replace `df` with your DataFrame name\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5521d322-1cbf-410a-b4f8-bdf4e944e1f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Finding missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a00f46-3339-4600-b90e-5631f9ef12a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr  \n",
    "import numpy as np \n",
    "\n",
    "# Replace 'your_file.nc' with the actual file path\n",
    "your_dataset = xr.open_dataset('your_file.nc')  \n",
    "\n",
    "# Replace 'your_time_variable' with the name of the time variable in your NetCDF file\n",
    "time = your_dataset['your_time_variable']  \n",
    "\n",
    "# Convert the numeric time values to datetime format\n",
    "base_date = np.datetime64('2002-01-01T00:00:00') # Define the base date (replace this with the base date if needed, here it's set to 2002-01-01)\n",
    "time_values = time[:]  \n",
    "time_datetimes = base_date + np.timedelta64(1, 'D') * time_values  \n",
    "time_np = time_datetimes.values  \n",
    "\n",
    "# Generate the expected sequence of monthly time steps between the minimum and maximum time points\n",
    "start_time = time_np.min() \n",
    "end_time = time_np.max()  \n",
    "expected_times = np.arange(start_time, end_time, np.timedelta64(1, 'M'), dtype='datetime64[M]')  \n",
    "missing_times = np.setdiff1d(expected_times, time_np.astype('datetime64[M]')) \n",
    "missing_numerical_time_steps = ((missing_times - base_date) / np.timedelta64(1, 'D')).astype(int)  \n",
    "\n",
    "# Print the missing numerical time steps\n",
    "print(\"Missing numerical time steps:\")  \n",
    "for missing_time_step in missing_numerical_time_steps:\n",
    "    print(missing_time_step)  # Print each missing time step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f362c98-cf82-4bc5-91fa-22689f80ccef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Interpolate NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3803f5b-ab9b-407e-815e-263f11270ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate NaN values using interpolation\n",
    "\n",
    "# Replace 'df' with your actual DataFrame name containing NaN values\n",
    "df = df.interpolate(method='linear')  # You can change 'linear' to another interpolation method if needed\n",
    "\n",
    "# Display the resulting DataFrame with interpolated values\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b145cb0-81b8-465a-83af-8a50887d9d4d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Clipping the data for shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bddd3c8-4c4f-4733-aa19-b6bca257c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr  \n",
    "import geopandas as gpd  \n",
    "from affine import Affine  \n",
    "from rasterio.features import geometry_mask  \n",
    "\n",
    "# Function to calculate the transform from the coordinates\n",
    "def calculate_transform(ds):\n",
    "    lon = ds['lon'].values  \n",
    "    lat = ds['lat'].values  \n",
    "    lon_res = (lon[1] - lon[0])  \n",
    "    lat_res = (lat[1] - lat[0])  \n",
    "    transform = Affine.translation(lon[0] - lon_res / 2, lat[0] - lat_res / 2) * Affine.scale(lon_res, lat_res)\n",
    "    return transform\n",
    "\n",
    "# Function to clip NetCDF data using a shapefile\n",
    "def clip_netcdf_with_shapefile(ds, shapefile):\n",
    "    transform = calculate_transform(ds)\n",
    "    geoms = shapefile.geometry.values  \n",
    "    mask = geometry_mask([geom for geom in geoms],  \n",
    "                         transform=transform,  \n",
    "                         invert=True,  \n",
    "                         out_shape=(ds.dims['lat'], ds.dims['lon']))\n",
    "    \n",
    "    mask_da = xr.DataArray(mask, dims=(\"lat\", \"lon\"), coords={\"lat\": ds[\"lat\"], \"lon\": ds[\"lon\"]})\n",
    "    clipped_ds = ds.where(mask_da, drop=True)  \n",
    "    return clipped_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e32f32-99c6-4b3e-9b80-681f4ce0aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "nc_file_path = \"D:/path/to/your_nc_file.nc\"  # Replace with the path to your NetCDF file\n",
    "shapefile_path = \"D:/path/to/your_shapefile.shp\"  # Replace with the path to your shapefile\n",
    "shapefile = gpd.read_file(shapefile_path) \n",
    "ds = xr.open_dataset(nc_file_path, engine='netcdf4')  \n",
    "\n",
    "# Clip the NetCDF data\n",
    "clipped_ds = clip_netcdf_with_shapefile(ds, shapefile)  # Call the clipping function\n",
    "\n",
    "# Save the clipped data to a new NetCDF file\n",
    "clipped_ds.to_netcdf('path/to/your_output_file.nc', engine='netcdf4')  # Specify the output file path where the clipped data will be saved\n",
    "\n",
    "print(\"Clipping completed and saved to 'path/to/your_output_file.nc'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a537b-3559-4e49-82fd-c3d819ed9db1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Unit conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17ba017-60d3-4e80-9897-d12a4869b1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame with the following columns:\n",
    "# 'Variable1' is in meters (m), 'Variable2' is in cubic meters per hour (mÂ³/hr),\n",
    "# 'Variable3' is in centimeters (cm), and 'Variable4' is in cubic meters per second (mÂ³/sec).\n",
    "\n",
    "# Convert 'Variable1' from meters (m) to millimeters (mm)\n",
    "df['Variable1_mm'] = df['Variable1'] * 1000          # 1 meter = 1000 millimeters\n",
    "\n",
    "# Convert 'Variable2' from cubic meters per hour (mÂ³/hr) to cubic meters per second (mÂ³/sec)\n",
    "df['Variable2_m3_sec'] = df['Variable2'] / 3600      # 1 hour = 3600 seconds\n",
    "\n",
    "# Convert 'Variable3' from centimeters (cm) to feet (ft)\n",
    "df['Variable3_ft'] = df['Variable3'] / 30.48         # 1 foot = 30.48 centimeters\n",
    "\n",
    "# Convert 'Variable4' from cubic meters per second (mÂ³/sec) to cubic feet per second (ftÂ³/sec)\n",
    "df['Variable4_ft3_sec'] = df['Variable4'] * 35.3147  # 1 mÂ³ = 35.3147 ftÂ³\n",
    "\n",
    "# Display the DataFrame with the new columns\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddce2345-ba8c-401b-bdfc-2350d3682d0c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Merging the NetCDF4 files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb144d9-9ce4-41d8-b9e3-2745e253d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import xarray as xr  \n",
    "\n",
    "# File paths for your NetCDF files (replace these with actual file paths if necessary)\n",
    "filepaths = [\n",
    "    \"your_nc_file1.nc4\",  \n",
    "    \"your_nc_file2.nc4\",  \n",
    "    \"your_nc_file3.nc4\"  \n",
    "]\n",
    "\n",
    "# Merge the specified NetCDF files by their coordinates\n",
    "merged_ds = xr.open_mfdataset(filepaths, combine='by_coords')\n",
    "merged_filepath = \"your_merged_file.nc\"  # Define the path to save the merged NetCDF file\n",
    "merged_ds.to_netcdf(merged_filepath)  \n",
    "\n",
    "# Print a success message to confirm the file has been saved\n",
    "print(\"Merged file saved successfully:\", merged_filepath)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5f7488-beb4-4e0e-a1b2-6913cbe5efad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Splitting the NetCDF4 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c4584-859e-415e-9d8d-61d66793dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr  \n",
    "\n",
    "# Replace 'your_nc_file.nc' with your actual file path\n",
    "nc_file = \"your_nc_file.nc\"\n",
    "ds = xr.open_dataset(nc_file)  \n",
    "\n",
    "# Split the data based on time\n",
    "\n",
    "# For example >> If 'your_nc_file.nc' has data from 1980-2020 \n",
    "# If we want to split the original file into two files from 1980-2000 and  2001-2020.\n",
    "\n",
    "# Select data from 1980 to 2000\n",
    "ds_1980_2000 = ds.sel(time=slice('1980-01-01', '2000-12-31'))  \n",
    "\n",
    "# Select data from 2001 to 2020\n",
    "ds_2001_2020 = ds.sel(time=slice('2001-01-01', '2020-12-31'))  \n",
    "\n",
    "# Define file paths for the split files\n",
    "split_file_1 = \"split_file_1980_2000.nc\"  # Path for the first split file\n",
    "split_file_2 = \"split_file_2001_2020.nc\"  # Path for the second split file\n",
    "\n",
    "# Save the split datasets to separate NetCDF files\n",
    "ds_1980_2000.to_netcdf(split_file_1)  # Save the 1980-2000 dataset\n",
    "ds_2001_2020.to_netcdf(split_file_2)  # Save the 2001-2020 dataset\n",
    "\n",
    "# Print confirmation messages to indicate successful saving\n",
    "print(f\"First split file saved successfully: {split_file_1}\")  \n",
    "print(f\"Second split file saved successfully: {split_file_2}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824875eb-52b2-4f51-a090-d23fe646fcc2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Spatial plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c075292-0f00-4f96-a291-c8f9d0c152a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### For World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8f9708-9720-4f44-9f16-a1ff9afae9db",
   "metadata": {},
   "source": [
    "##### Spatial Averaging by latitude and Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ec6c4-6d2e-4e52-9373-4b586f2d91e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Replace 'df' with the actual name of your DataFrame\n",
    "# Replace 'lat with your actual latitude column name\n",
    "# Replace 'lon' with your actual longitude column name\n",
    "averaged_df = df.groupby(['lat', 'lon']).mean().reset_index()\n",
    "\n",
    "# Display the resulting DataFrame with the average values for each latitude and longitude\n",
    "averaged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c2e5d1-4e57-4fa1-98f0-d1c0c1712781",
   "metadata": {},
   "source": [
    "##### Spatial Plot of Spatial Averaged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0d87c4-7264-411a-b45a-5586e5edd2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "from mpl_toolkits.basemap import Basemap  \n",
    "import numpy as np  \n",
    "\n",
    "# Function to create the plot\n",
    "def create_plot(color_scale, color_map):\n",
    "    plt.figure(figsize=(10, 8))  # Create a new figure with specified size\n",
    "\n",
    "# Available map projection types: ['robin', 'mill', 'merc', 'tmerc', 'aea', 'lcc', 'stere', 'aeqd', 'laea', 'moll', 'sinu', 'goes', 'wink3', 'fll', 'eck4', 'aitoff']\n",
    "\n",
    "    # Initializing a Basemap with Robinson projection\n",
    "    m = Basemap(projection='robin', resolution='c', lat_0=0, lon_0=0)\n",
    "    \n",
    "    # Drawing map boundaries and features\n",
    "    m.drawcoastlines() \n",
    "    m.drawcountries()  \n",
    "    m.fillcontinents(color='lightgray', lake_color='white')  \n",
    "    m.drawmapboundary(fill_color='white')  \n",
    "    \n",
    "    # Convert lat/lon to map projection coordinates\n",
    "    x, y = m(averaged_df['lon'].values, averaged_df['lat'].values) \n",
    "    \n",
    "    ### Replace 'variable name' with your data column name ###\n",
    "    sc = m.scatter(x, y, c=averaged_df['variable name'], cmap=color_map, vmin=-color_scale, vmax=color_scale, s=5, alpha=0.7)  \n",
    "\n",
    "    # Adding colorbar\n",
    "    cbar = plt.colorbar(sc, label='Variable Name', extend='both', shrink=0.6) ### Set label name as required ###\n",
    "    cbar.ax.invert_yaxis()  \n",
    "    \n",
    "    plt.title('Spatial Plot of Variable Name Data')  ### Set plot title ###\n",
    "    plt.savefig('output_figure.png', dpi=300)        ### Save the plot  ###\n",
    "    plt.show()                                       # Display the plot \n",
    "\n",
    "# Set your desired color scale and colormap\n",
    "color_scale = 30        # Example value for color scale\n",
    "\n",
    "# Color map options : ['PiYG', 'PRGn', 'BrBG', 'PuOr', 'RdGy', 'jet_r', 'RdBu', 'RdYlBu', 'RdYlGn', 'Spectral', 'coolwarm', 'bwr', 'seismic']\n",
    "color_map = 'Spectral'  # Choose a color map option\n",
    "\n",
    "# Create the plot\n",
    "create_plot(color_scale, color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ca817-cb06-4f22-9d54-e8d5cabc1e10",
   "metadata": {},
   "source": [
    "#### For Shape file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f23540-c970-4e46-ae6b-365de4db6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import xarray as xr \n",
    "import geopandas as gpd  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt  \n",
    "import cartopy.crs as ccrs  \n",
    "from shapely.geometry import Point  \n",
    "from scipy.interpolate import griddata  \n",
    "from matplotlib.font_manager import FontProperties  \n",
    "\n",
    "ds = xr.open_dataset(r\"your_file_path.nc\")    ### Replace 'your_file_path.nc' with the path to your NetCDF file\n",
    "spatial_df= ds.to_dataframe().reset_index()\n",
    "shapefile_path = r\"your_shapefile_path.shp\"   ### Replace 'your_shapefile_path.shp' with the path to your shapefile\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Calculate mean values for a specific variable \n",
    "spatial_df['mean_variable'] = spatial_df[['your variable']].mean(axis=1)  ### Replace 'your variable' and 'mean_variable' with your variable name ###\n",
    "\n",
    "# Group by latitude and longitude and compute the mean\n",
    "averaged_df = spatial_df.groupby(['lat', 'lon']).mean().reset_index()     # Replace 'lat' and 'lon' with your latitude and longitude column names\n",
    "\n",
    "# Extract averaged latitude, longitude, and variable values\n",
    "latitudes = averaged_df['lat'].values  \n",
    "longitudes = averaged_df['lon'].values  \n",
    "avg_values = averaged_df['mean_variable'].values                        \n",
    "\n",
    "min_lon, min_lat, max_lon, max_lat = gdf.total_bounds \n",
    "\n",
    "# Create a mesh grid covering the entire area of the shapefile\n",
    "# Change the 'num_lon' and 'num_lat' for smoothing variations \n",
    "num_lon = 500  \n",
    "num_lat = 500  \n",
    "grid_lons = np.linspace(min_lon, max_lon, num_lon)  \n",
    "grid_lats = np.linspace(min_lat, max_lat, num_lat)  \n",
    "grid_lons, grid_lats = np.meshgrid(grid_lons, grid_lats)  \n",
    "interpolated_variable = griddata((longitudes, latitudes), avg_values, (grid_lons, grid_lats), method='linear')  \n",
    "\n",
    "# Create a PlateCarree projection for mapping\n",
    "projection = ccrs.PlateCarree()\n",
    "\n",
    "# Create a mask for points within the shapefile polygons\n",
    "mask = np.zeros_like(interpolated_variable, dtype=bool)  \n",
    "points = np.vstack([grid_lons.ravel(), grid_lats.ravel()]).T \n",
    "for geom in gdf.geometry:\n",
    "    mask = mask | np.array([geom.contains(Point(x, y)) for x, y in points]).reshape(grid_lons.shape)  \n",
    "interpolated_variable[~mask] = np.nan  \n",
    "\n",
    "# Plotting the figure\n",
    "plt.figure(figsize=(8, 8))            ### Set figure size\n",
    "ax = plt.axes(projection=projection)  \n",
    "\n",
    "# Add gridlines with customization\n",
    "gridlines = ax.gridlines(draw_labels=False, color='gray', linestyle='--', linewidth=0.5, zorder=1)  \n",
    "gridlines.top_labels = False  \n",
    "gridlines.right_labels = False\n",
    "gridlines.xlabel_style = {'size': 20, 'color': 'black', 'weight': 'bold'}  \n",
    "gridlines.ylabel_style = {'size': 20, 'color': 'black', 'weight': 'bold'}  \n",
    "\n",
    "# Plot the interpolated data\n",
    "### Adjust color map('cmap') and range('vmin' and 'vmax')\n",
    "pcm = ax.pcolormesh(grid_lons, grid_lats, interpolated_variable, cmap='Spectral', transform=projection, vmin=25, vmax=310, zorder=2)  \n",
    "\n",
    "# Add color bar with a heading\n",
    "cbar = plt.colorbar(pcm, ax=ax, orientation='vertical', shrink=0.6)  \n",
    "cbar.set_label('your variable', fontsize=20, fontweight='bold', color='black')  ### Replace 'your variable' with required colorbar label ###\n",
    "\n",
    "# Customize color bar ticks\n",
    "cbar.ax.yaxis.set_tick_params(labelsize=20, width=1.5, color='black', labelcolor='black')  \n",
    "tick_font = FontProperties(weight='bold', size=20)  \n",
    "cbar.ax.yaxis.set_ticklabels(cbar.ax.yaxis.get_ticklabels(), fontproperties=tick_font)  \n",
    "\n",
    "# Add shapefile polygons to the map\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='black', zorder=3)  \n",
    "\n",
    "# Set latitude and longitude tick labels with direction\n",
    "lat_step = 4  # Control the number of latitude ticks\n",
    "lon_step = 7  # Control the number of longitude ticks\n",
    "ax.set_xticks(np.arange((np.floor(min_lon), np.ceil(max_lon) + 1, lon_step))                # Set x-axis ticks\n",
    "ax.set_yticks(np.arange(np.floor(min_lat), np.ceil(max_lat) + 1, lat_step))                 # Set y-axis ticks\n",
    "ax.set_xticklabels([f\"{abs(int(x))}Â°{'E' if x > 0 else 'W'}\" for x in ax.get_xticks()], fontsize=20, fontweight='bold', color='black')  # Format x-axis labels\n",
    "ax.set_yticklabels([f\"{abs(int(y))}Â°{'N' if y > 0 else 'S'}\" for y in ax.get_yticks()], fontsize=20, fontweight='bold', color='black')  # Format y-axis labels\n",
    "\n",
    "# Set the plot extent\n",
    "ax.set_extent([min_lon, max_lon, min_lat, max_lat], crs=projection)  \n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('output_plot.tiff', dpi=300, bbox_inches='tight', facecolor='white')           # Save figure as TIFF file\n",
    "plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f805de7-cd4f-4e56-a886-e74891525f2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Spatial plotting for single time step using the index number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e5af5-784d-4efe-abf3-7ff911de11f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import geopandas as gpd  \n",
    "import matplotlib.pyplot as plt  \n",
    "import cartopy.crs as ccrs  \n",
    "import xarray as xr  \n",
    "from cartopy.mpl.gridliner import LATITUDE_FORMATTER, LONGITUDE_FORMATTER  \n",
    "from scipy.interpolate import griddata  \n",
    "from matplotlib.font_manager import FontProperties  \n",
    "from shapely.geometry import Point  # Import Point class\n",
    "\n",
    "# Load NetCDF data and shapefile\n",
    "your_nc_data = xr.open_dataset(\"grace data/clip1_anjigrace.nc\")  # Replace with actual NetCDF file path\n",
    "your_shapefile = gpd.read_file(\"Export_Output.shp\")              # Replace with actual shapefile path\n",
    "\n",
    "# Specify time index\n",
    "time_index = 11  # Change as needed\n",
    "\n",
    "# Convert data to DataFrame and calculate mean\n",
    "spatial_df = your_nc_data.to_dataframe().reset_index()\n",
    "spatial_df['mean_variable'] = spatial_df[['your variable']].mean(axis=1)  ### Replace 'your variable' and 'mean_variable' with your variable name ### \n",
    "\n",
    "# Group by latitude and longitude\n",
    "averaged_df = spatial_df.groupby(['lat', 'lon']).mean().reset_index()\n",
    "\n",
    "# Extract averaged values\n",
    "latitudes = averaged_df['lat'].values  \n",
    "longitudes = averaged_df['lon'].values  \n",
    "avg_values = averaged_df['mean_variable'].values                        \n",
    "\n",
    "min_lon, min_lat, max_lon, max_lat = your_shapefile.total_bounds \n",
    "\n",
    "# Create mesh grid\n",
    "num_lon, num_lat = 500, 500  \n",
    "grid_lons = np.linspace(min_lon, max_lon, num_lon)  \n",
    "grid_lats = np.linspace(min_lat, max_lat, num_lat)  \n",
    "grid_lons, grid_lats = np.meshgrid(grid_lons, grid_lats)  \n",
    "\n",
    "# Interpolate variable\n",
    "interpolated_variable = griddata((longitudes, latitudes), avg_values, (grid_lons, grid_lats), method='linear')\n",
    "\n",
    "# Create PlateCarree projection for mapping\n",
    "projection = ccrs.PlateCarree()\n",
    "\n",
    "# Create a mask for points within the shapefile\n",
    "mask = np.zeros_like(interpolated_variable, dtype=bool)  \n",
    "points = np.vstack([grid_lons.ravel(), grid_lats.ravel()]).T \n",
    "for geom in your_shapefile.geometry:\n",
    "    mask = mask | np.array([geom.contains(Point(x, y)) for x, y in points]).reshape(grid_lons.shape)  \n",
    "interpolated_variable[~mask] = np.nan  \n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 8))  ### Set figure size ###\n",
    "ax = plt.axes(projection=projection)  \n",
    "\n",
    "# Add gridlines\n",
    "gridlines = ax.gridlines(draw_labels=True, color='gray', linestyle='--', linewidth=0.5, zorder=1)  \n",
    "gridlines.top_labels = False  \n",
    "gridlines.right_labels = False\n",
    "gridlines.xlabel_style = {'size': 20, 'color': 'black', 'weight': 'bold'}  \n",
    "gridlines.ylabel_style = {'size': 20, 'color': 'black', 'weight': 'bold'}  \n",
    "\n",
    "# Plot the interpolated data\n",
    "pcm = ax.pcolormesh(grid_lons, grid_lats, interpolated_variable, cmap='Spectral', transform=projection)  \n",
    "\n",
    "# Add color bar\n",
    "cbar = plt.colorbar(pcm, ax=ax, orientation='vertical', shrink=0.6)  \n",
    "cbar.set_label('your variable', fontsize=20, fontweight='bold', color='black')   ### Replace 'your variable' with required colorbar label ###\n",
    "\n",
    "# Customize color bar ticks\n",
    "cbar.ax.yaxis.set_tick_params(labelsize=20, width=1.5, color='black', labelcolor='black')  \n",
    "tick_font = FontProperties(weight='bold', size=20)  \n",
    "cbar.ax.yaxis.set_ticklabels(cbar.ax.yaxis.get_ticklabels(), fontproperties=tick_font)  \n",
    "\n",
    "# Add shapefile polygons\n",
    "your_shapefile.plot(ax=ax, facecolor='none', edgecolor='black', zorder=3)  \n",
    "\n",
    "# Set latitude and longitude tick labels\n",
    "lat_step = 4  \n",
    "lon_step = 7  \n",
    "ax.set_xticks(np.arange(np.floor(min_lon), np.ceil(max_lon) + 1, lon_step))  \n",
    "ax.set_yticks(np.arange(np.floor(min_lat), np.ceil(max_lat) + 1, lat_step))  \n",
    "ax.set_xticklabels([f\"{abs(int(x))}Â°{'E' if x > 0 else 'W'}\" for x in ax.get_xticks()], fontsize=20, fontweight='bold', color='black')  \n",
    "ax.set_yticklabels([f\"{abs(int(y))}Â°{'N' if y > 0 else 'S'}\" for y in ax.get_yticks()], fontsize=20, fontweight='bold', color='black')  \n",
    "\n",
    "# Set the plot extent\n",
    "ax.set_extent([min_lon, max_lon, min_lat, max_lat], crs=projection)  \n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('output_plot.tiff', dpi=300, bbox_inches='tight', facecolor='white')  \n",
    "plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c90279-2aef-4b27-855b-081bda987ff2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Time series analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b2dc4a-cb63-4aa9-93fd-4aa80d3bd5a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Trend analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb734aed-d762-418f-ad4d-b7acd3f4409d",
   "metadata": {},
   "outputs": [],
   "source": [
    " import pandas as pd  \n",
    "import netCDF4 as nc  \n",
    "import numpy as np  \n",
    "\n",
    "file_path = \"your_file.nc\"                       # Replace 'your_file.nc' with the path to your actual NetCDF file\n",
    "\n",
    "# Open the NetCDF file for reading\n",
    "with nc.Dataset(file_path, 'r') as dataset:  \n",
    "    time_var = dataset.variables['time'][:]      # Replace 'time' with the actual variable name for the time in your file\n",
    "    lat_var = dataset.variables['lat'][:]        # Replace 'lat' with the actual variable name for latitude\n",
    "    lon_var = dataset.variables['lon'][:]        # Replace 'lon' with the actual variable name for longitude\n",
    "    data_var = dataset.variables['variable'][:]  # Replace 'variable' with the actual variable name for data\n",
    "\n",
    "time_2d, lat_2d, lon_2d = np.meshgrid(time_var, lat_var, lon_var, indexing='ij')  \n",
    "data_1d = data_var.flatten()  \n",
    "df = pd.DataFrame({                              # Replace 'df' with the name you want to initialize for your DataFrame\n",
    "    'time': time_2d.flatten(),  \n",
    "    'lat': lat_2d.flatten(),   \n",
    "    'lon': lon_2d.flatten(),    \n",
    "    'variable': data_1d        \n",
    "})\n",
    "df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac200fa7-f57a-45d6-94e7-a6b9fb2e9338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.dates as mdates  \n",
    "import seaborn as sns  \n",
    "from scipy.stats import linregress  \n",
    "\n",
    "# Calculate the trend line for the average data\n",
    "### Replace 'df' with your actual DataFrame name and 'average' with the name you want for average data ###\n",
    "slope_mean, intercept_mean, r_value_mean, p_value_mean, std_err_mean = linregress(df.index, df['average'])  \n",
    "trend_line_mean = intercept_mean + slope_mean * df.index  \n",
    "\n",
    "# Print the slope of the trend line\n",
    "print(f\"Slope of the trend line: {slope_mean:.3f} mm/month\")  \n",
    "sns.set(style=\"whitegrid\")  \n",
    "\n",
    "### Create a figure for the plot ###\n",
    "plt.figure(figsize=(14, 8))   \n",
    "\n",
    "# Replace 'df' with your DataFrame and 'average' with your column name for average data\n",
    "plt.plot(df['datetime'], df['average'], label='Mean P', color='#FF5733', linewidth=2)  \n",
    "\n",
    "# Plot the trend line for the mean precipitation\n",
    "df['datetime'] = pd.to_datetime(df['time'])\n",
    "plt.plot(df['datetime'], trend_line_mean, color='blue', linestyle='--', label='Mean P Trend Line')  \n",
    "\n",
    "# Replace 'min' and 'max' with the appropriate column names for minimum and maximum of your data \n",
    "plt.fill_between(df['datetime'], df['min'], df['max'], color='lightgray', alpha=0.5, label='Range of P')  \n",
    "\n",
    "# Formatting the x-axis to display specific years\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))  # Set x-axis to show year format\n",
    "plt.gca().xaxis.set_major_locator(mdates.YearLocator()) \n",
    "specific_years = [1999, 2002, 2005, 2008, 2011, 2014, 2017, 2020, 2023]  ### You can choose to display which years you want on x axis ###\n",
    "plt.xticks(pd.to_datetime(specific_years, format='%Y'), fontsize=28, fontweight='bold', color='black')  \n",
    "\n",
    "# Label the x-axis\n",
    "plt.xlabel('Year', fontsize=28, fontweight='bold', color='black')  \n",
    "\n",
    "# Formatting the y-axis\n",
    "plt.yticks(fontsize=28, fontweight='bold', color='black')  \n",
    "plt.ylim(min(df['average'].min(), trend_line_mean.min()), max(df['average'].max(), trend_line_mean.max())) \n",
    "\n",
    "# Label the y-axis\n",
    "plt.ylabel('Your variable', fontsize=28, fontweight='bold', color='black')  \n",
    "\n",
    "# Customize the legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()  \n",
    "handles.append(plt.Line2D([0], [0], color='none'))  \n",
    "plt.legend(handles=handles, loc='upper left', frameon=False, fancybox=False, shadow=False, prop={'size': 28, 'weight':'bold'}, ncol=2)  \n",
    "\n",
    "# Add grid lines and customize the axis spines\n",
    "plt.grid(True, which='both', linestyle=':', linewidth=0.5, color='gray')  \n",
    "plt.gca().spines['right'].set_color('black')  \n",
    "plt.gca().spines['bottom'].set_color('black')  \n",
    "plt.gca().spines['left'].set_color('black')  \n",
    "\n",
    "# Replace 'df' with your DataFrame\n",
    "plt.xlim(left=df['datetime'].min(), right=df['datetime'].max())  \n",
    "\n",
    "### Set the title of the plot ### \n",
    "plt.title('Plot Title', fontsize=16, fontweight='bold')  \n",
    "\n",
    "# Save the plot as a .tiff file\n",
    "plt.savefig('Output_file.tiff', dpi=300, bbox_inches='tight')  # Replace 'Output_file.tiff' with your desired file name when saving the plot\n",
    "\n",
    "# Display the plot\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c529865-71ba-4127-834d-93df66e5a8b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Trend change point analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edf5e9a-eb00-46df-99d1-8b13ef057523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import netCDF4 as nc  \n",
    "import numpy as np  \n",
    "\n",
    "file_path = \"your_file.nc\"                       # Replace 'your_file.nc' with the path to your actual NetCDF file\n",
    "\n",
    "# Open the NetCDF file for reading\n",
    "with nc.Dataset(file_path, 'r') as dataset:  \n",
    "    time_var = dataset.variables['time'][:]      # Replace 'time' with the actual variable name for the time in your file\n",
    "    lat_var = dataset.variables['lat'][:]        # Replace 'lat' with the actual variable name for latitude\n",
    "    lon_var = dataset.variables['lon'][:]        # Replace 'lon' with the actual variable name for longitude\n",
    "    data_var = dataset.variables['variable'][:]  # Replace 'variable' with the actual variable name for data\n",
    "\n",
    "time_2d, lat_2d, lon_2d = np.meshgrid(time_var, lat_var, lon_var, indexing='ij')  \n",
    "data_1d = data_var.flatten()  \n",
    "df = pd.DataFrame({                              # Replace 'df' with the name you want to initialize for your DataFrame\n",
    "    'time': time_2d.flatten(),  \n",
    "    'lat': lat_2d.flatten(),   \n",
    "    'lon': lon_2d.flatten(),    \n",
    "    'variable': data_1d        \n",
    "})\n",
    "df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a36c0-d6cb-47e9-94f1-2181091e5d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import ruptures as rpt\n",
    "\n",
    "# Replace 'df' with the actual DataFrame name in your analysis\n",
    "df['datetime'] = pd.to_datetime(df['time'])  \n",
    "df.set_index('datetime', inplace=True)  \n",
    "df['Year'] = df.index.year + df.index.dayofyear / 365  \n",
    "df['Month'] = df['Year'] * 12  \n",
    "\n",
    "# Detect change points in the average data using the PELT method with an RBF kernel\n",
    "\n",
    "signal = df['variable name'].values       ### Replace 'variable name' with your variable name ###\n",
    "algo = rpt.Pelt(model=\"rbf\").fit(signal)  # Apply PELT method for change point detection using the Radial Basis Function (RBF) model\n",
    "change_points = algo.predict(pen=6)       ### Adjust the penalty value to control the sensitivity of change point detection ###\n",
    "\n",
    "plt.figure(figsize=(14, 8))               ### Set the figure size ###\n",
    "\n",
    "# Replace the 'your variable' with your variable name\n",
    "plt.plot(df['Month'], df['your variable'], label='Variable Name', color='#FF5733', linewidth=2)  # Change the color code as per your requirment\n",
    "\n",
    "# Replace the 'min', 'max' and 'your variable' with your variable maximum and minimum column name and variable column name \n",
    "plt.fill_between(df['Month'], df['min'], df['max'], color='lightgray', alpha=0.7, label='Range of your variable')  \n",
    "\n",
    "# Plot vertical lines at detected change points\n",
    "for cp in change_points[:-1]:  \n",
    "    plt.axvline(df['Month'].iloc[cp], color='purple', linestyle='--', label='Change Point' if cp == change_points[0] else \"\")  \n",
    "trend_colors = ['blue', 'green', 'orange', 'purple']  \n",
    "\n",
    "# Calculate and plot linear trend lines for each segment between change points\n",
    "time_values = df['Month'].values.reshape(-1, 1)  \n",
    "previous_cp = 0  \n",
    "slopes = []  \n",
    "handles = []  \n",
    "labels = []  \n",
    "\n",
    "# Loop through each change point to create segments\n",
    "for idx, cp in enumerate(change_points):  \n",
    "    segment = slice(previous_cp, cp) \n",
    "    model_segment = LinearRegression().fit(time_values[segment], df['average'].values[segment])  # Fit a linear regression model to the segment\n",
    "    slope = model_segment.coef_[0]  \n",
    "    slopes.append(slope)  \n",
    "    trend_label = f'Trend {idx + 1}'  \n",
    "    handles.append(plt.Line2D([0], [0], linestyle='--', color=trend_colors[idx % len(trend_colors)], label=trend_label))  \n",
    "    plt.plot(df['Month'].values[segment], model_segment.predict(time_values[segment]), linestyle='--', color=trend_colors[idx % len(trend_colors)], label=trend_label)  \n",
    "    previous_cp = cp  \n",
    "\n",
    "# Print slopes of each segment\n",
    "for i, slope in enumerate(slopes):  \n",
    "    print(f\"Slope of Trend {i + 1}: {slope:.3f} mm/month\")  \n",
    "\n",
    "# Add a legend to the plot with 3 rows per column\n",
    "handles, labels = plt.gca().get_legend_handles_labels()  \n",
    "\n",
    "# Arrange handles and labels for a 2-column layout with 3 rows per column\n",
    "plt.legend(handles=handles, labels=labels, loc='upper left', bbox_to_anchor=(0.0, 1.02), \n",
    "           frameon=False, fancybox=False, shadow=False, prop={'size': 28, 'weight': 'bold'}, \n",
    "           ncol=2, handlelength=2.5, handletextpad=1, columnspacing=2) \n",
    "\n",
    "# Label x and y axes\n",
    "plt.xlabel('Year', fontsize=28, fontweight='bold', color='black')  \n",
    "plt.ylabel('Variable Name', fontsize=28, fontweight='bold', color='black')  \n",
    "\n",
    "# Customize x and y ticks\n",
    "plt.xticks(fontsize=28, fontweight='bold', color='black')  \n",
    "plt.yticks(fontsize=28, fontweight='bold', color='black')  \n",
    "\n",
    "\n",
    "specific_years = [1999, 2002, 2005, 2008, 2011, 2014, 2017, 2020, 2023]   ### Set specific years as x-ticks ###\n",
    "specific_months = [year * 12 for year in specific_years] \n",
    "plt.xticks(specific_months, specific_years)  \n",
    "\n",
    "# Set the limits for the x and y axes\n",
    "plt.xlim(df['Month'].min(), df['Month'].max())  \n",
    "plt.ylim(0, 210)  \n",
    "\n",
    "# Enhance grid and spines for a cleaner appearance\n",
    "plt.grid(True, which='both', linestyle=':', linewidth=0.5, color='gray') \n",
    "plt.gca().spines['top'].set_color('black') \n",
    "plt.gca().spines['right'].set_color('black') \n",
    "plt.gca().spines['bottom'].set_color('black')  \n",
    "plt.gca().spines['left'].set_color('black')  \n",
    "\n",
    "# Save the plot as a TIFF file\n",
    "plt.savefig('your_filename.tiff', dpi=2000, bbox_inches='tight', facecolor='white')  # Replace 'your_filename.tiff' with the desired filename when saving the plot\n",
    "\n",
    "# Show the plot\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ed547f-89dd-4582-b4ae-5530c07ed4b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Seasonal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5823151a-61c0-4ca0-a300-f952b4936218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import netCDF4 as nc  \n",
    "import numpy as np  \n",
    "\n",
    "file_path = \"your_file.nc\"                       # Replace 'your_file.nc' with the path to your actual NetCDF file\n",
    "\n",
    "# Open the NetCDF file for reading\n",
    "with nc.Dataset(file_path, 'r') as dataset:  \n",
    "    time_var = dataset.variables['time'][:]      # Replace 'time' with the actual variable name for the time in your file\n",
    "    lat_var = dataset.variables['lat'][:]        # Replace 'lat' with the actual variable name for latitude\n",
    "    lon_var = dataset.variables['lon'][:]        # Replace 'lon' with the actual variable name for longitude\n",
    "    data_var = dataset.variables['variable'][:]  # Replace 'variable' with the actual variable name for data\n",
    "\n",
    "time_2d, lat_2d, lon_2d = np.meshgrid(time_var, lat_var, lon_var, indexing='ij')  \n",
    "data_1d = data_var.flatten()  \n",
    "df = pd.DataFrame({                              # Replace 'df' with the name you want to initialize for your DataFrame\n",
    "    'time': time_2d.flatten(),  \n",
    "    'lat': lat_2d.flatten(),   \n",
    "    'lon': lon_2d.flatten(),    \n",
    "    'variable': data_1d        \n",
    "})\n",
    "df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ed58f9-17c0-4bb7-bdf2-4c459ebb6dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'df' is the DataFrame with a column 'your variable'\n",
    "\n",
    "# Plot the seasonality data for one dataset\n",
    "plt.figure(figsize=(14, 8))  \n",
    "\n",
    "# Plot the 'your variable' column from the DataFrame\n",
    "plt.plot(df.index, df['your variable'], marker='o', label='Mean SMS', linewidth=2.5)  \n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Your Variable Name Seasonality for One Dataset', fontsize=16, fontweight='bold')  ### Change the title as per your requirement ###\n",
    "plt.xlabel('Month', fontsize=26, fontweight='bold', color='black')  \n",
    "plt.ylabel('Your Variable', fontsize=26, fontweight='bold', color='black')                   ### Replace 'Your Variable' with the actual variable name ###\n",
    "plt.xticks(np.arange(1, 13), \n",
    "           ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n",
    "           fontsize=26, fontweight='bold', color='black')  \n",
    "plt.yticks(fontsize=26, fontweight='bold', color='black')  \n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1, 1.0), prop={'size': 26, 'weight': 'bold'}, frameon=False)  \n",
    "\n",
    "# Enhance grid and spines for better visibility\n",
    "plt.grid(True, which='both', linestyle=':', linewidth=0.5, color='gray')  \n",
    "plt.gca().spines['top'].set_color('black')  \n",
    "plt.gca().spines['right'].set_color('black')  \n",
    "plt.gca().spines['bottom'].set_color('black')  \n",
    "plt.gca().spines['left'].set_color('black')  \n",
    "\n",
    "# Set x-axis limits from 1 to 12 (for months)\n",
    "plt.xlim(1, 12)  \n",
    "plt.tight_layout()  \n",
    "\n",
    "# Replace 'your_filename.tiff' with the desired filename when saving the plot\n",
    "plt.savefig('your_filename.tiff', dpi=200, bbox_inches='tight') \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9eca9580-8c3b-4b02-948c-319166ddf983",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'your_dataframe' is the DataFrame with columns 'average', 'max', and 'min'\n",
    "# Replace 'your_dataframe' with the actual name of your DataFrame.\n",
    "\n",
    "# Plot the seasonality data\n",
    "plt.figure(figsize=(14, 8))  \n",
    "# Replace the 'average' and 'your_dataframe' with your variable average column name and your dataframe name\n",
    "plt.plot(your_dataframe.index, your_dataframe['average'], marker='o', label='Mean SMS', linewidth=2.5)  \n",
    "\n",
    "# Fill the area between the 'max' and 'min' values\n",
    "plt.fill_between(your_dataframe.index, your_dataframe['max'], your_dataframe['min'], color='grey', alpha=0.2, label='Range of your variable')  \n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Your variable name Seasonality of Seven Datasets with Max-Min Range', fontsize=16, fontweight='bold')  # Change the title as per your requirment\n",
    "plt.xlabel('Month', fontsize=26, fontweight='bold', color='black')  \n",
    "plt.ylabel('Your variable', fontsize=26, fontweight='bold', color='black')  # Replace 'your variable' with your original variable name \n",
    "plt.xticks(np.arange(1, 13), \n",
    "           ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n",
    "           fontsize=26, fontweight='bold', color='black')  \n",
    "plt.yticks(fontsize=26, fontweight='bold', color='black')  \n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1, 1.0), prop={'size': 26, 'weight': 'bold'}, frameon=False)  \n",
    "\n",
    "# Enhance grid and spines for better visibility\n",
    "plt.grid(True, which='both', linestyle=':', linewidth=0.5, color='gray')  \n",
    "plt.gca().spines['top'].set_color('black')  \n",
    "plt.gca().spines['right'].set_color('black')  \n",
    "plt.gca().spines['bottom'].set_color('black')  \n",
    "plt.gca().spines['left'].set_color('black')  \n",
    "\n",
    "plt.xlim(1, 12)  # Set x-axis limits from 1 to 12 (for months)\n",
    "plt.tight_layout()  \n",
    "\n",
    "# Replace 'your_filename.tiff' with the desired filename when saving the plot\n",
    "plt.savefig('your_filename.tiff', dpi=200, bbox_inches='tight') \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af2a073-9ffd-4238-9b3a-3c57512a4f02",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Residual error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd1f941-0e1b-4294-8bed-21a1223d5c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a monthly averaged dataframe with variables P, ET, Runoff and Î”S\n",
    "\n",
    "# Calculate the residual by subtracting ET, runoff, and Î”S from precipitation\n",
    "\n",
    "### Chnage the below variable names with your actual variable names ###\n",
    "residual_df['res'] = residual_df['precip'] - residual_df['et'] - residual_df['runoff'] - residual_df['deltaS']\n",
    "\n",
    "# Group the residual_df by month and calculate the mean for each month\n",
    "residual_season = residual_df.groupby('month').mean().reset_index()  \n",
    "\n",
    "# Display the resulting DataFrame containing monthly averages\n",
    "residual_season\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd7e977-6ce2-4d59-b2fc-a904e224a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "\n",
    "# Define the columns you want to plot (replace with your variable names)\n",
    "columns_to_plot = ['precip', 'et', 'runoff', 'deltaS', 'res'] \n",
    "\n",
    "# Define a dictionary to map column names to specific colors for the plot\n",
    "colors = {\n",
    "    'precip': '#1f77b4',  \n",
    "    'et': '#ff7f0e',      \n",
    "    'runoff': '#2ca02c', \n",
    "    'deltaS': '#d62728', \n",
    "    'residual': '#9467bd'     \n",
    "}\n",
    "\n",
    "# Define a dictionary to map original column names to human-readable legend names\n",
    "legend_names = {\n",
    "    'precip': 'Precipitation',  \n",
    "    'et': 'ET',                 \n",
    "    'runoff': 'Runoff',         \n",
    "    'deltaS': 'Î”S',             \n",
    "    'residual': 'Residual'           \n",
    "}\n",
    "\n",
    "plt.figure(figsize=(14, 8))  ### Set the figure size ### \n",
    "\n",
    "# Loop through each column \n",
    "for column in columns_to_plot:\n",
    "    plt.plot(\n",
    "        residual_season['month'],    \n",
    "        residual_season[column],     \n",
    "        color=colors[column],       \n",
    "        linestyle='--' if column != 'residual' else '-',  # Solid line for residual, dashed for others\n",
    "        linewidth=3 if column == 'residual' else 2,       # Thicker line for residual\n",
    "        label=legend_names[column]  \n",
    "    )\n",
    "\n",
    "# Customize plot axes labels and their appearance\n",
    "plt.xlabel('Month', fontsize=18, fontweight='bold', color='black')  \n",
    "plt.ylabel('Value (mm/month)', fontsize=18, fontweight='bold', color='black')  \n",
    "\n",
    "# Set custom ticks for the X-axis to show month names\n",
    "plt.xticks(\n",
    "    np.arange(1, 13),  \n",
    "    ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],  \n",
    "    fontsize=18, fontweight='bold', color='black'  \n",
    ")\n",
    "\n",
    "# Set font settings for Y-axis ticks\n",
    "plt.yticks(fontsize=18, fontweight='bold', color='black')\n",
    "\n",
    "# Add a legend to the plot with custom font size and position\n",
    "plt.legend(\n",
    "    prop={'size': 18, 'weight': 'bold'},  \n",
    "    loc='upper center',  \n",
    "    bbox_to_anchor=(0.5, 1.0),  \n",
    "    ncol=2  # Use two columns for the legend\n",
    ")\n",
    "\n",
    "# Add a grid with specific settings to the plot\n",
    "plt.grid(True, which='both', linestyle=':', linewidth=0.5, color='gray')  \n",
    "\n",
    "# Customize the appearance of the plot spines \n",
    "plt.gca().spines['top'].set_color('black')  \n",
    "plt.gca().spines['right'].set_color('black')  \n",
    "plt.gca().spines['bottom'].set_color('black')  \n",
    "plt.gca().spines['left'].set_color('black')  \n",
    "\n",
    "# Set the X-axis limits to ensure it covers from January (1) to December (12)\n",
    "plt.xlim(1, 12)\n",
    "\n",
    "# Tighten the layout to reduce white space\n",
    "plt.tight_layout()\n",
    "\n",
    "# Replace 'your_residual_seasonal_change_plot.tiff' with the desired filename when saving the plot\n",
    "plt.savefig('your_residual_seasonal_change_plot.tiff', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449c7bf2-a233-41c6-999b-e914dc7448f9",
   "metadata": {},
   "source": [
    "### Validation with observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3455734-8eb1-4f6d-b33c-37d276d48275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt  \n",
    "import matplotlib.cm as cm  \n",
    "\n",
    "# Define a TaylorDiagram class\n",
    "class TaylorDiagram:\n",
    "    def __init__(self, refstd, fig=None, rect=111, label=''):\n",
    "        self.refstd = refstd  \n",
    "        self.fig = fig if fig is not None else plt.figure()  \n",
    "        self.ax = self.fig.add_subplot(rect, polar=True)  \n",
    "        self.ax.set_theta_zero_location('N')  \n",
    "        self.ax.set_theta_direction(-1)  \n",
    "\n",
    "        # Plot reference point and standard deviation contour\n",
    "        self.ax.plot([0], [refstd], 'ko', label=label)  \n",
    "        l, = self.ax.plot(np.linspace(0, np.pi/2), [refstd]*50, 'k--')  \n",
    "        l.set_dashes([2, 2]) \n",
    "\n",
    "        # Set axis limits and labels\n",
    "        self.ax.set_ylim(0, 1.5*refstd)  \n",
    "        self.ax.set_xlim(0, np.pi/2)  \n",
    "\n",
    "        # Configure grid and ticks\n",
    "        self.ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{np.cos(x):.2f}'))  \n",
    "        self.ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.2f}'))  \n",
    "\n",
    "        # Labels for the diagram\n",
    "        self.ax.set_xlabel('Standard Deviation', fontsize=14, fontweight='bold')  \n",
    "        self.ax.set_ylabel('Standard Deviation', fontsize=14, fontweight='bold')  \n",
    "\n",
    "        # Add correlation axis label\n",
    "        self.add_correlation_axis_label()\n",
    "\n",
    "    def add_correlation_axis_label(self):\n",
    "        # Add a label for the correlation axis\n",
    "        self.ax.text(np.pi/4, self.refstd * 1.2, 'Correlation', fontsize=14, fontweight='bold', color='black', ha='center', va='center')\n",
    "\n",
    "    def add_sample(self, stddev, corrcoef, rmse, label=None, **kwargs):\n",
    "        theta = np.arccos(corrcoef)  \n",
    "        self.ax.plot(theta, stddev, 'o', label=label, **kwargs)  \n",
    "\n",
    "    def add_grid(self):\n",
    "        self.ax.grid(True)  \n",
    "\n",
    "    def add_legend(self):\n",
    "        # Add a legend to the plot\n",
    "        legend = self.ax.legend(loc='upper right', bbox_to_anchor=(1.65, 0.95))\n",
    "        for text in legend.get_texts():\n",
    "            text.set_fontsize(14)\n",
    "            text.set_fontweight('bold')\n",
    "            text.set_color('black')\n",
    "\n",
    "# Function to compute standard deviation, correlation coefficient, and RMSE\n",
    "def compute_metrics(obs, model):\n",
    "    stddev = np.std(model)  \n",
    "    corrcoef = np.corrcoef(obs, model)[0, 1]  \n",
    "    rmse = np.sqrt(np.mean((obs - model)**2))  \n",
    "    return stddev, corrcoef, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4219d8-054b-45fe-8880-eeac1b838b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame named 'df' containing all the datasets \n",
    "# that you want to use for model validation, including the observed variable \n",
    "\n",
    "observed_column = \"Observed_Variable\"            ### Replace \"Observed_Variable\" with your observed variable name ###\n",
    "# Replace df with your actual DataFrame\n",
    "model_columns = [col for col in df.columns if col not in [observed_column, 'datetime', 'month']]\n",
    "\n",
    "print(\"Model columns:\", model_columns)\n",
    "\n",
    "# Convert all columns to numeric (use errors='coerce' to handle non-numeric entries)\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Check for NaN or Inf values in the observed data\n",
    "nan_count = df[observed_column].isna().sum()\n",
    "inf_count = np.isinf(df[observed_column]).sum()\n",
    "\n",
    "print(f\"NaN values in observed data: {nan_count}\")\n",
    "print(f\"Inf values in observed data: {inf_count}\")\n",
    "\n",
    "if nan_count > 0 or inf_count > 0:\n",
    "    # Handle NaN or Inf values\n",
    "    df[observed_column].fillna(df[observed_column].mean(), inplace=True)\n",
    "    df.replace([np.inf, -np.inf], df[observed_column].mean(), inplace=True)\n",
    "\n",
    "# Compute metrics for observation and each model\n",
    "obs = df[observed_column].values\n",
    "obs_std = np.std(obs)\n",
    "\n",
    "print(f\"Standard deviation of observed data: {obs_std}\")\n",
    "\n",
    "# Check if obs_std is a valid number\n",
    "if not np.isfinite(obs_std):\n",
    "    raise ValueError(\"Standard deviation of observed data is not finite.\")\n",
    "\n",
    "models_metrics = {}  # Dictionary to store metrics for each model\n",
    "colors = cm.get_cmap('tab20', len(model_columns))\n",
    "\n",
    "for idx, col in enumerate(model_columns):\n",
    "    model_values = df[col].values\n",
    "    std, corr, rmse = compute_metrics(obs, model_values)\n",
    "    \n",
    "    # Skip models with NaN values\n",
    "    if np.isnan(std) or np.isnan(corr) or np.isnan(rmse):\n",
    "        print(f\"Skipping {col} due to NaN values\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing {col} - stddev: {std}, correlation: {corr}, rmse: {rmse}\")\n",
    "    models_metrics[col] = (std, corr, rmse)\n",
    "\n",
    "# Plotting Taylor diagram\n",
    "fig = plt.figure(figsize=(12, 8))  # Create figure with specified size\n",
    "dia = TaylorDiagram(obs_std, fig=fig, label='Observation')\n",
    "\n",
    "for idx, (model, (std, corr, rmse)) in enumerate(models_metrics.items()):\n",
    "    print(f\"Plotting {model} with stddev: {std}, correlation: {corr}\")\n",
    "    dia.add_sample(std, corr, rmse, label=model, color=colors(idx))\n",
    "\n",
    "dia.add_grid()\n",
    "dia.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ced40ef-6791-4590-a4cb-bc347e954fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c738fa1-21c9-4241-ae56-1e94308beba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
